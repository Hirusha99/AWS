{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hirusha99/AWS/blob/main/Predictions_AWS_Sagemaker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b2d6cc",
      "metadata": {
        "id": "29b2d6cc"
      },
      "source": [
        "### Importing Important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4b8559",
      "metadata": {
        "id": "7a4b8559",
        "outputId": "2d41526c-d436-4c46-fd4e-3ad0d0eba47a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
            "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
          ]
        }
      ],
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
        "from sagemaker.session import s3_input, Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61f178d",
      "metadata": {
        "id": "e61f178d",
        "outputId": "d30a2128-3213-46ad-c0ad-5a3f881bc8a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "us-east-1\n"
          ]
        }
      ],
      "source": [
        "bucket_name = 'bankappication' # unique name for bucket\n",
        "my_region = boto3.session.Session().region_name # set region of the instance\n",
        "print(my_region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2ed568",
      "metadata": {
        "id": "ad2ed568",
        "outputId": "1ddeaf82-6eba-45e2-902b-d5ab7a503e51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "S3 Bucket created successfully!\n"
          ]
        }
      ],
      "source": [
        "s3 = boto3.resource('s3')\n",
        "\n",
        "try:\n",
        "    if my_region == 'us-east-1':\n",
        "        s3.create_bucket(Bucket = bucket_name)\n",
        "    print('S3 Bucket created successfully!')\n",
        "except Exception as e:\n",
        "    print(\" S3 error :\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57fa2433",
      "metadata": {
        "id": "57fa2433",
        "outputId": "67040751-1be1-4c39-ef50-abeeffc5dba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s3://bankappication/xgboost-as-a-built-in-algo/output\n"
          ]
        }
      ],
      "source": [
        "# set output path where the trained model will be save\n",
        "prefix = 'xgboost-as-a-built-in-algo' # algorithm\n",
        "output_path = 's3://{}/{}/output'.format(bucket_name,prefix)\n",
        "print(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88534eaa",
      "metadata": {
        "id": "88534eaa"
      },
      "source": [
        "### Downloading the dataSet and storing in S3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56bb9670",
      "metadata": {
        "id": "56bb9670",
        "outputId": "ad17b3e4-0590-4dc2-eaed-85bbdad1a6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success : downloaded bank_clean.csv\n",
            "Success: Data loaded into dataframe.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import urllib\n",
        "\n",
        "try:\n",
        "\n",
        "    print('Success : downloaded bank_clean.csv')\n",
        "except Exception as e :\n",
        "    print('Data load error :',e)\n",
        "\n",
        "try :\n",
        "    model_data = pd.read_csv('./bank_clean.csv',index_col=0) # index_col -> first column of the CSV file should be used as the index of the DataFrame.\n",
        "    print('Success: Data loaded into dataframe.')\n",
        "except Exception as e:\n",
        "    print(\"Data load error:\",e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e220b3d8",
      "metadata": {
        "id": "e220b3d8",
        "outputId": "16a32765-cd34-49fa-f9a9-46770d6196b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28831, 61) (12357, 61)\n"
          ]
        }
      ],
      "source": [
        "### train test split\n",
        "\n",
        "import numpy as np\n",
        "# value of 1 for frac means that you want to include all rows in your sample.\n",
        "train_data , test_data = np.split(model_data.sample(frac = 1 , random_state = 1729),[int(0.7 * len (model_data))]) # training size should be 70%\n",
        "print(train_data.shape,test_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d01adbd",
      "metadata": {
        "id": "5d01adbd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "pd.concat([train_data['y_yes'],train_data.drop(['y_yes','y_no'],\n",
        "                                              axis = 1)],\n",
        "         axis = 1).to_csv('train.csv',index = False, header = False)\n",
        "\n",
        "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix,'train/train.csv')).upload_file('train.csv')\n",
        "\n",
        "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f7b53c",
      "metadata": {
        "id": "d6f7b53c"
      },
      "outputs": [],
      "source": [
        "pd.concat([test_data['y_yes'],test_data.drop(['y_yes','y_no'],\n",
        "                                              axis = 1)],\n",
        "         axis = 1).to_csv('test.csv',index = False, header = False)\n",
        "\n",
        "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix,'test/test.csv')).upload_file('test.csv')\n",
        "\n",
        "s3_input_test = sagemaker.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd79efc0",
      "metadata": {
        "id": "fd79efc0"
      },
      "source": [
        "### Building model Xgboost - Inbuilt Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fd2ba29",
      "metadata": {
        "id": "2fd2ba29",
        "outputId": "470527e0-3ca6-4ab5-932c-7dfc3a83dcd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The method get_image_uri has been renamed in sagemaker>=2.\n",
            "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
          ]
        }
      ],
      "source": [
        "# this line automatically looks for the XGBoost image URI and builds an XGBoost container\n",
        "# specify the repo_version depending on your preference\n",
        "\n",
        "container = get_image_uri(boto3.Session().region_name,\n",
        "                         'xgboost',\n",
        "                         repo_version= '1.0-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfbb2f1f",
      "metadata": {
        "id": "cfbb2f1f"
      },
      "outputs": [],
      "source": [
        "# initialize hyperparameter\n",
        "hyperparameters = {\n",
        "    \"max_depth\":\"5\",\n",
        "    \"eta\": \"0.2\",\n",
        "    \"gamma\" : \"4\",\n",
        "    \"min_child_weight\": \"6\",\n",
        "    \"subsample\": \"0.7\",\n",
        "    \"objective\":\"binary:logistic\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2854cb5e",
      "metadata": {
        "id": "2854cb5e"
      },
      "outputs": [],
      "source": [
        "# construct a SageMaker estimator that calls the xgboost-container\n",
        "estimator = sagemaker.estimator.Estimator(image_uri=container,\n",
        "                                          hyperparameters=hyperparameters,\n",
        "                                          role=sagemaker.get_execution_role(),\n",
        "                                          instance_type='ml.t3.medium',\n",
        "                                          instance_count=1,\n",
        "                                          volume_size=5, # 5 GB\n",
        "                                          output_path=output_path,\n",
        "                                          use_spot_instances = True,\n",
        "                                          max_run = 300,\n",
        "                                          max_wait = 600\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a829f6",
      "metadata": {
        "id": "47a829f6",
        "outputId": "bcea6b9a-5050-47ee-d337-ed0636c1e085"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-02-14-09-58-17-629\n"
          ]
        },
        {
          "ename": "ClientError",
          "evalue": "An error occurred (ValidationException) when calling the CreateTrainingJob operation: 1 validation error detected: Value 'ml.t3.medium' at 'resourceConfig.instanceType' failed to satisfy constraint: Member must satisfy enum value set: [ml.m6i.xlarge, ml.trn1.32xlarge, ml.p2.xlarge, ml.m5.4xlarge, ml.m4.16xlarge, ml.m6i.12xlarge, ml.p5.48xlarge, ml.m6i.24xlarge, ml.p4d.24xlarge, ml.g5.2xlarge, ml.c5n.xlarge, ml.p3.16xlarge, ml.m5.large, ml.m6i.16xlarge, ml.p2.16xlarge, ml.g5.4xlarge, ml.c4.2xlarge, ml.c5.2xlarge, ml.c6i.32xlarge, ml.c4.4xlarge, ml.c6i.xlarge, ml.g5.8xlarge, ml.c5.4xlarge, ml.c6i.12xlarge, ml.c5n.18xlarge, ml.g4dn.xlarge, ml.c6i.24xlarge, ml.g4dn.12xlarge, ml.c4.8xlarge, ml.g4dn.2xlarge, ml.c6i.2xlarge, ml.c6i.16xlarge, ml.c5.9xlarge, ml.g4dn.4xlarge, ml.c6i.4xlarge, ml.c5.xlarge, ml.g4dn.16xlarge, ml.c4.xlarge, ml.trn1n.32xlarge, ml.g4dn.8xlarge, ml.c6i.8xlarge, ml.g5.xlarge, ml.c5n.2xlarge, ml.g5.12xlarge, ml.g5.24xlarge, ml.c5n.4xlarge, ml.trn1.2xlarge, ml.c5.18xlarge, ml.p3dn.24xlarge, ml.m6i.2xlarge, ml.g5.48xlarge, ml.g5.16xlarge, ml.p3.2xlarge, ml.m6i.4xlarge, ml.m5.xlarge, ml.m4.10xlarge, ml.c5n.9xlarge, ml.m5.12xlarge, ml.m4.xlarge, ml.m5.24xlarge, ml.m4.2xlarge, ml.m6i.8xlarge, ml.m6i.large, ml.p2.8xlarge, ml.m5.2xlarge, ml.m6i.32xlarge, ml.p4de.24xlarge, ml.p3.8xlarge, ml.m4.4xlarge]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_input_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_input_test\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py:1338\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_for_training(job_name\u001b[38;5;241m=\u001b[39mjob_name)\n\u001b[1;32m   1337\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[0;32m-> 1338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job \u001b[38;5;241m=\u001b[39m \u001b[43m_TrainingJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n",
            "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py:2434\u001b[0m, in \u001b[0;36m_TrainingJob.start_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new Amazon SageMaker training job from the estimator.\u001b[39;00m\n\u001b[1;32m   2410\u001b[0m \n\u001b[1;32m   2411\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;124;03m    all information about the started training job.\u001b[39;00m\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2432\u001b[0m train_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_args(estimator, inputs, experiment_config)\n\u001b[0;32m-> 2434\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(estimator\u001b[38;5;241m.\u001b[39msagemaker_session, estimator\u001b[38;5;241m.\u001b[39m_current_job_name)\n",
            "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:977\u001b[0m, in \u001b[0;36mSession.train\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, training_image_config, infra_check_config, container_entry_point, container_arguments, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy, remote_debug_config)\u001b[0m\n\u001b[1;32m    974\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_training_job(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest)\n\u001b[0;32m--> 977\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:6163\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   6146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   6147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6148\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6151\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   6152\u001b[0m ):\n\u001b[1;32m   6153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   6154\u001b[0m \n\u001b[1;32m   6155\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6161\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   6162\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:975\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    973\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating training-job with name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, job_name)\n\u001b[1;32m    974\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m--> 975\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_training_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:553\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:1009\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
            "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateTrainingJob operation: 1 validation error detected: Value 'ml.t3.medium' at 'resourceConfig.instanceType' failed to satisfy constraint: Member must satisfy enum value set: [ml.m6i.xlarge, ml.trn1.32xlarge, ml.p2.xlarge, ml.m5.4xlarge, ml.m4.16xlarge, ml.m6i.12xlarge, ml.p5.48xlarge, ml.m6i.24xlarge, ml.p4d.24xlarge, ml.g5.2xlarge, ml.c5n.xlarge, ml.p3.16xlarge, ml.m5.large, ml.m6i.16xlarge, ml.p2.16xlarge, ml.g5.4xlarge, ml.c4.2xlarge, ml.c5.2xlarge, ml.c6i.32xlarge, ml.c4.4xlarge, ml.c6i.xlarge, ml.g5.8xlarge, ml.c5.4xlarge, ml.c6i.12xlarge, ml.c5n.18xlarge, ml.g4dn.xlarge, ml.c6i.24xlarge, ml.g4dn.12xlarge, ml.c4.8xlarge, ml.g4dn.2xlarge, ml.c6i.2xlarge, ml.c6i.16xlarge, ml.c5.9xlarge, ml.g4dn.4xlarge, ml.c6i.4xlarge, ml.c5.xlarge, ml.g4dn.16xlarge, ml.c4.xlarge, ml.trn1n.32xlarge, ml.g4dn.8xlarge, ml.c6i.8xlarge, ml.g5.xlarge, ml.c5n.2xlarge, ml.g5.12xlarge, ml.g5.24xlarge, ml.c5n.4xlarge, ml.trn1.2xlarge, ml.c5.18xlarge, ml.p3dn.24xlarge, ml.m6i.2xlarge, ml.g5.48xlarge, ml.g5.16xlarge, ml.p3.2xlarge, ml.m6i.4xlarge, ml.m5.xlarge, ml.m4.10xlarge, ml.c5n.9xlarge, ml.m5.12xlarge, ml.m4.xlarge, ml.m5.24xlarge, ml.m4.2xlarge, ml.m6i.8xlarge, ml.m6i.large, ml.p2.8xlarge, ml.m5.2xlarge, ml.m6i.32xlarge, ml.p4de.24xlarge, ml.p3.8xlarge, ml.m4.4xlarge]"
          ]
        }
      ],
      "source": [
        "estimator.fit({'train': s3_input_train,'validation': s3_input_test})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2917d2",
      "metadata": {
        "id": "fe2917d2"
      },
      "source": [
        "### Deploy Machine Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "929b6d1b",
      "metadata": {
        "id": "929b6d1b"
      },
      "outputs": [],
      "source": [
        "xgb_predictor = estimator.deploy(initial_instance_count = 1,instance_type= 'ml.t3.micro')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31cc633b",
      "metadata": {
        "id": "31cc633b"
      },
      "source": [
        "### Prediction of the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e943665",
      "metadata": {
        "id": "4e943665"
      },
      "outputs": [],
      "source": [
        "from sagemaker.predictor import csv_serializer\n",
        "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
        "xgb_predictor.content_type = 'text/csv' # set the data type for an inference (model content type)\n",
        "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
        "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
        "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
        "print(predictions_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26fb142e",
      "metadata": {
        "id": "26fb142e"
      },
      "outputs": [],
      "source": [
        "predictions_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc5b628",
      "metadata": {
        "id": "0fc5b628"
      },
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "\n",
        "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
        "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
        "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
        "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
        "print(\"Observed\")\n",
        "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
        "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d11d297b",
      "metadata": {
        "id": "d11d297b"
      },
      "source": [
        "### Delete Endpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2a97dd",
      "metadata": {
        "id": "6d2a97dd",
        "outputId": "4b3a54ac-c765-4dd4-f7a6-13e761ac4822"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'ResponseMetadata': {'RequestId': 'DJZYRCGMQ7QHEHD0',\n",
              "   'HostId': 'FHmEveIiZE/zz8IO4BOtlXQPyh8iYcinufr6D2oa9FYqzl1z282xpxr8wpxv1xdUv0fDW0gI3TVM5iqoumkk8A==',\n",
              "   'HTTPStatusCode': 200,\n",
              "   'HTTPHeaders': {'x-amz-id-2': 'FHmEveIiZE/zz8IO4BOtlXQPyh8iYcinufr6D2oa9FYqzl1z282xpxr8wpxv1xdUv0fDW0gI3TVM5iqoumkk8A==',\n",
              "    'x-amz-request-id': 'DJZYRCGMQ7QHEHD0',\n",
              "    'date': 'Wed, 14 Feb 2024 11:00:22 GMT',\n",
              "    'content-type': 'application/xml',\n",
              "    'transfer-encoding': 'chunked',\n",
              "    'server': 'AmazonS3',\n",
              "    'connection': 'close'},\n",
              "   'RetryAttempts': 0},\n",
              "  'Deleted': [{'Key': 'xgboost-as-a-built-in-algo/train/train.csv'},\n",
              "   {'Key': 'xgboost-as-a-built-in-algo/test/test.csv'}]}]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
        "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
        "bucket_to_delete.objects.all().delete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d372d15c",
      "metadata": {
        "id": "d372d15c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}